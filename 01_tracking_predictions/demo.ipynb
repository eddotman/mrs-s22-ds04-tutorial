{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Tracking ML Model Predictions\n",
    "\n",
    "In this tutorial notebook, we'll examine some examples of why we may want to track model predictions, and how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the `SynthesizabilityModel` class. This is a toy model (i.e. random number generator) that is meant to stand-in for a binary ML classifier, predicting the chance that some hypothetical material should be synthesizable or not.\n",
    "\n",
    "**Q: Can you navigate to the class definition? What kinds of methods does the class provide?**\n",
    "\n",
    "\n",
    "_Hint: You'll need to look at another file in this folder to understand the model definition._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SynthesizabilityModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with a list of materials\n",
    "\n",
    "Let's now start by defining a _list_ of materials by their formulas, along with an instance of our imported model class.\n",
    "\n",
    "**Q: If you'd like, try adding some other materials in the list, or otherwise modifying the list of materials.**\n",
    "\n",
    "**Q: What happens if you add a material that isn't a string? Why does this happen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_materials = [\n",
    "    \"Li7La3(SnO6)2\",\n",
    "    \"Li3(WO3)8\",\n",
    "    \"Li4Mn2P4H3O16\",\n",
    "    \"Li2Ni(PO3)5\",\n",
    "    \"MgV2O4\",\n",
    "]\n",
    "\n",
    "predictor = SynthesizabilityModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running predictions\n",
    "\n",
    "Let's run the prediction function in a loop over the list of materials. \n",
    "\n",
    "**Q: Are the results deterministic (do they change when you re-run)? Why or why not?**\n",
    "\n",
    "**Q: Try timing the runtime -- e.g., uncomment the `%%time` at the start of the next code block. How long does it take to run predictions on these materials? If you had 1 billion material candidates to run predictions on, would you do anything differently?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The synthesizability score for Li7La3(SnO6)2 is 0.04.\n",
      "The synthesizability score for Li3(WO3)8 is 0.72.\n",
      "The synthesizability score for Li4Mn2P4H3O16 is 0.26.\n",
      "The synthesizability score for Li2Ni(PO3)5 is 0.24.\n",
      "The synthesizability score for MgV2O4 is 0.41.\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "for material in my_materials:\n",
    "    print (\n",
    "        f\"The synthesizability score for {material} is\",\n",
    "        f\"{round(predictor.predict_single(material), 2)}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions from the past\n",
    "\n",
    "So far, we've played around with a toy model and thought a little bit about running predictions at larger scales. \n",
    "\n",
    "In many cases, machine learning involves multiple teams where the predictions are a handoff point between different groups. \n",
    "\n",
    "How can we understand and manage predictions, when they were made by a model that someone else built? (e.g., a previous grad student, a collaborator from another lab).\n",
    "\n",
    "Let's first take a look at a single predictions file, provided to us by another researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"synthesizability_predictions\": {\n",
      "    \"Li7La3(SnO6)2\": 0.15,\n",
      "    \"Li3(WO3)8\": 0.39,\n",
      "    \"Li4Mn2P4H3O16\": 1.0,\n",
      "    \"Li2Ni(PO3)5\": 1.0,\n",
      "    \"MgV2O4\": 0.22\n",
      "  },\n",
      "  \"citation\": \"https://www.nature.com/articles/s43246-021-00219-x\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/predictions_v1.json\", \"r\") as prediction_file:\n",
    "    print(json.dumps(\n",
    "        json.load(prediction_file),\n",
    "        indent=2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: What kinds of materials are these? If you were running an experimental lab group, which of these materials might you start thinking about how to synthesize? Why?**\n",
    "\n",
    "_Hint: take a look at the article_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing predictions\n",
    "\n",
    "There are two other predictions files you've received from your collaborators, and you haven't had a chance to get a hold of the grad student that produced the original predictions.\n",
    "\n",
    "Let's take a look at all of these prediction files side by side. Printing out the entire JSONs makes it tricky to compare... is there a better way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                   \n",
    "\n",
    "files = [\n",
    "    \"data/predictions_v1.json\",\n",
    "    \"data/predictions_v2.json\",\n",
    "    \"data/predictions_final.json\",\n",
    "]\n",
    "\n",
    "all_predictions = pandas.concat([           # Concatenate several Series...\n",
    "        pandas.read_json(f)                 # Read the JSON file to Pandas\n",
    "        [\"synthesizability_predictions\"]    # Select the sub-dictionary as a Series\n",
    "        .rename(f)                          # Rename this Series to the filename\n",
    "        for f in files                      # Do this for all files in the list\n",
    "    ], axis=1)                              # Concatenate into a table (not a line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is somewhat simplified and overly-concise, but is an example of a classic data transformation pipeline. Each of the different data source files are read-in, we use the filenames to keep track of where each prediction came from, and we filter to a single column of data, and join everything together.\n",
    "\n",
    "Let's take a look at the predictions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data/predictions_v1.json</th>\n",
       "      <th>data/predictions_v2.json</th>\n",
       "      <th>data/predictions_final.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Li2Ni(PO3)5</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li3(WO3)8</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li4Mn2P4H3O16</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li7La3(SnO6)2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MgV2O4</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               data/predictions_v1.json  data/predictions_v2.json  \\\n",
       "Li2Ni(PO3)5                        1.00                      1.00   \n",
       "Li3(WO3)8                          0.39                      0.93   \n",
       "Li4Mn2P4H3O16                      1.00                      0.99   \n",
       "Li7La3(SnO6)2                      0.15                      0.95   \n",
       "MgV2O4                             0.22                      0.98   \n",
       "\n",
       "               data/predictions_final.json  \n",
       "Li2Ni(PO3)5                           0.10  \n",
       "Li3(WO3)8                             0.93  \n",
       "Li4Mn2P4H3O16                         1.00  \n",
       "Li7La3(SnO6)2                         0.15  \n",
       "MgV2O4                                0.22  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q: Which version of the predictions is the \"right\" one?**\n",
    "\n",
    "**Q: How was the \"final\" version of the predictions made, and how does it relate to v1 and v2?**\n",
    "\n",
    "**Q: Which materials would you select to make in a lab? Is it the same choice you made before? Are you as confident as you were before in your choice?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The key takeaway\n",
    "\n",
    "Treating predictions as single numbers is dangerous, because it makes them very hard to reproduce and understand!\n",
    "\n",
    "Instead, think of predictions as being **as important as a model**. Remember at the start of this notebook, we took the time to understand and look up the model definition -- let's consider what might be the case if you did this for predictions as well.\n",
    "\n",
    "Let's look at two examples of structured, rich prediction objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_id\": \"27f49604-99df-4c90-91c2-353d8ae1295f\",\n",
      "  \"prediction_id\": \"28fb2aea-84bf-4e4e-9d9e-51f8dfc6228a\",\n",
      "  \"citation\": \"https://www.nature.com/articles/s43246-021-00219-x\",\n",
      "  \"prediction_result\": {\n",
      "    \"type\": \"binary_classification\",\n",
      "    \"name\": \"synthesizability\",\n",
      "    \"value\": 0.39\n",
      "  },\n",
      "  \"prediction_input\": {\n",
      "    \"name\": \"Li3(WO3)8\",\n",
      "    \"mp_id\": \"mp-1222771_Li\",\n",
      "    \"material_id\": \"768a747c-015c-482c-acdf-bd4e7bbb4936\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/structured_prediction_1295f_6228a.json\", \"r\") as prediction_file:\n",
    "    print(json.dumps(\n",
    "        json.load(prediction_file),\n",
    "        indent=2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_id\": \"159c7941-15c3-4bc2-83f2-71f6b87fee96\",\n",
      "  \"prediction_id\": \"1485d58c-f70d-443d-9b79-b19d34f19f22\",\n",
      "  \"citation\": \"https://www.nature.com/articles/s43246-021-00219-x\",\n",
      "  \"prediction_result\": {\n",
      "    \"type\": \"binary_classification\",\n",
      "    \"name\": \"synthesizability\",\n",
      "    \"value\": 0.42\n",
      "  },\n",
      "  \"prediction_input\": {\n",
      "    \"name\": \"Li3(WO3)8\",\n",
      "    \"mp_id\": \"mp-1222771_Li\",\n",
      "    \"material_id\": \"768a747c-015c-482c-acdf-bd4e7bbb4936\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/structured_prediction_fee96_19f22.json\", \"r\") as prediction_file:\n",
    "    print(json.dumps(\n",
    "        json.load(prediction_file),\n",
    "        indent=2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see if you are able to answer the following, by referencing against the above two structured prediction files...\n",
    "\n",
    "**Q: Were these two predictions made by the same, or different models? How do you know?**\n",
    "\n",
    "**Q: If you had to aggregate many of these prediction files, and select only the predictions from a particular model, how would you do that? (Bonus: Can you do it in Python code?)**\n",
    "\n",
    "**Q: What was the input to these models when the prediction was made? Can you look up the material in an external database to verify exactly what the input is?**\n",
    "\n",
    "**Q: If you had to ask your collaborator (who built the models and the predictions) to double check a prediction, what would you send over if you wanted to know about: A) a single prediction, B) all the predictions from a single model, C) all the predictions on a single material?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we've learned\n",
    "\n",
    "Predictions are often stored and sent as \"lists of numbers,\" which can lead to very simple and efficient data pipelines and handoffs. However, this makes it difficult to track predictions and ensure reproducibility and explainability of our data.\n",
    "\n",
    "By thinking about each prediction at the same level of importance of a model, we can ensure that the appropriate metadata is packaged alongside a prediction, so that the provenance of each prediction is easy to understand and communicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d716a5cf5258362f30bb8395d3f92a585f7274919ab9a7024995604d68ea2302"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
